# 📁 K-Nearest Neighbors (KNN) Projects

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)]()
[![Made with scikit-learn](https://img.shields.io/badge/Made%20with-Scikit--Learn-F7931E.svg)](https://scikit-learn.org/)
[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HussamUmer/Machine-Learning)

Welcome to the **K-Nearest Neighbors (KNN)** section of this beginner-friendly ML repository!

KNN is one of the simplest algorithms out there — yet incredibly effective in both classification and regression tasks.  
It makes predictions by looking at the **'K' closest examples** in the training data.

---

## 📌 What is KNN?

KNN works by comparing the **distance** between input data and its neighbors.  
The majority label among the nearest neighbors decides the predicted class — just like asking your neighbors for advice!

No training phase, no fancy math — just **pure similarity**.

---

## 📊 Projects Included

### 1. 🌸 Iris Flower Classification  
Predict the species of an iris flower based on petal and sepal dimensions.

- 📄 Dataset: *Iris Dataset*  
- 🧠 Accuracy: **100%**  
- 🧪 Highlights: Clean dataset, 3-class classification, perfect for beginners

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HussamUmer/Machine-Learning/blob/main/K-Nearest%20Neighbors/Flower%20Species%20Prediction/Flower_Species_prediction.ipynb)

---

### 2. ✍️ Handwritten Digit Recognition  
Classify digits from 0–9 using image pixel data.

- 📄 Dataset: *Digit Recognizer Dataset* (Kaggle version of MNIST)  
- 🧠 Accuracy: **96%**  
- 🧪 Highlights: Image flattening, pixel-wise distance, visualization of predictions

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HussamUmer/Machine-Learning/blob/main/K-Nearest%20Neighbors/Hand%20Digit%20Recognition/Hand_written_digit_recognition.ipynb)

---

## 📚 What You'll Learn

✔️ How KNN classifies data using **proximity and voting**  
✔️ Working with **image data and structured data**  
✔️ Visualizing **decision boundaries** and accuracy

---

### 📏 Evaluation Metrics Used:
- Accuracy
- Confusion Matrix
- Visualization of Predictions

---

## 🛠 Tools & Libraries Used

- Python 3.10+
- pandas, numpy
- matplotlib, seaborn
- scikit-learn

---

## 💡 Why This Section Matters

KNN is one of the most **intuitive algorithms** to understand — no training needed, just **memorize and match**.  
These projects show how a simple idea can be **highly effective**, even on real-world problems like image classification.

---

> 🧠 Tip: Choosing the right value of **K** is crucial. Too low = noisy, too high = too generic!
