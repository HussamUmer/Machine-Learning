# 🌳 Random Forest Projects — Beginner Friendly!

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)]()
[![Made with scikit-learn](https://img.shields.io/badge/Made%20with-Scikit--Learn-F7931E.svg)](https://scikit-learn.org/)
[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HussamUmer/Machine-Learning)

Hey there! 👋  
This folder contains **beginner-friendly machine learning projects using the Random Forest algorithm** — one of the most powerful and easy-to-understand models in the ML world.

**Random Forest** builds multiple decision trees and lets them vote on the final output. It’s super useful when you want solid performance with minimal tuning!

---

## 📂 Projects Included

### ✅ 1. 🩺 Diabetes Prediction  
Predict whether a patient is likely to have diabetes based on diagnostic health data.

- 📄 Dataset: [Pima Indians Diabetes Dataset on Kaggle](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)  
- 🧠 Accuracy: **77.9%**  
- 🧪 Highlights: Feature scaling, class imbalance handling, performance metrics

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HussamUmer/Machine-Learning/blob/main/Random%20Forest/Diagnose%20Diabetes/Diagnose_Diabetes.ipynb)

---

### ✅ 2. 💳 Credit Card Fraud Detection  
Spot fraudulent transactions in credit card data — a classic imbalanced classification problem.

- 📄 Dataset: [Credit Card Fraud Detection Dataset on Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)  
- 🧠 Accuracy: **99.9%**  
- 🧪 Highlights: Heavy class imbalance, precision-recall tradeoff, under/oversampling techniques

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HussamUmer/Machine-Learning/blob/main/Random%20Forest/Credit%20Card%20Fraud%20Detection/Credit_card_fraud_detection.ipynb)

---

### ✅ 3. 🍷 Red Wine Quality Classification  
Predict wine quality based on chemical properties like acidity, sugar, and alcohol content.

- 📄 Dataset: [Red Wine Quality Dataset on Kaggle](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)  
- 🧠 Accuracy: **94.3%**  
- 🧪 Highlights: Feature importance, label simplification, multiclass classification

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HussamUmer/Machine-Learning/blob/main/Random%20Forest/Red%20wine%20Quality%20Prediction/Red_Wine_Quality_prediction.ipynb)

---

## 🔍 What You’ll Learn

Each project walks through the full ML pipeline, including:

1. 🧹 **Loading & Cleaning the Data**  
2. 📊 **Exploratory Data Analysis (EDA)** using colorful plots  
3. 🌲 **Training a Random Forest Classifier**  
4. ✅ **Model Evaluation** using accuracy, classification reports, confusion matrices  
5. 💾 **Saving Models** for reuse and deployment

No prior ML experience needed — everything is explained step-by-step.

---

## 🤔 Why Random Forest?

- 🌲 Combines many decision trees for better performance  
- 🧱 Robust to outliers and noise  
- 🔍 Reduces overfitting compared to single trees  
- 💪 Works well with both balanced and imbalanced datasets  
- 🧠 Offers feature importance out of the box!

---

## 🛠 Tools & Libraries Used

- Python 3.10+  
- pandas, numpy  
- seaborn, matplotlib  
- scikit-learn

---


